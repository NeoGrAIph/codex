diff --git a/codex-rs/otel/src/metrics/runtime_metrics.rs b/codex-rs/otel/src/metrics/runtime_metrics.rs
index d59ff4b1b..dbd28010f 100644
--- a/codex-rs/otel/src/metrics/runtime_metrics.rs
+++ b/codex-rs/otel/src/metrics/runtime_metrics.rs
@@ -1,7 +1,5 @@
 use crate::metrics::names::API_CALL_COUNT_METRIC;
 use crate::metrics::names::API_CALL_DURATION_METRIC;
-use crate::metrics::names::RESPONSES_API_INFERENCE_TIME_DURATION_METRIC;
-use crate::metrics::names::RESPONSES_API_OVERHEAD_DURATION_METRIC;
 use crate::metrics::names::SSE_EVENT_COUNT_METRIC;
 use crate::metrics::names::SSE_EVENT_DURATION_METRIC;
 use crate::metrics::names::TOOL_CALL_COUNT_METRIC;
@@ -34,8 +32,6 @@ pub struct RuntimeMetricsSummary {
     pub streaming_events: RuntimeMetricTotals,
     pub websocket_calls: RuntimeMetricTotals,
     pub websocket_events: RuntimeMetricTotals,
-    pub responses_api_overhead_ms: u64,
-    pub responses_api_inference_time_ms: u64,
 }
 
 impl RuntimeMetricsSummary {
@@ -45,8 +41,6 @@ impl RuntimeMetricsSummary {
             && self.streaming_events.is_empty()
             && self.websocket_calls.is_empty()
             && self.websocket_events.is_empty()
-            && self.responses_api_overhead_ms == 0
-            && self.responses_api_inference_time_ms == 0
     }
 
     pub(crate) fn from_snapshot(snapshot: &ResourceMetrics) -> Self {
@@ -70,18 +64,12 @@ impl RuntimeMetricsSummary {
             count: sum_counter(snapshot, WEBSOCKET_EVENT_COUNT_METRIC),
             duration_ms: sum_histogram_ms(snapshot, WEBSOCKET_EVENT_DURATION_METRIC),
         };
-        let responses_api_overhead_ms =
-            sum_histogram_ms(snapshot, RESPONSES_API_OVERHEAD_DURATION_METRIC);
-        let responses_api_inference_time_ms =
-            sum_histogram_ms(snapshot, RESPONSES_API_INFERENCE_TIME_DURATION_METRIC);
         Self {
             tool_calls,
             api_calls,
             streaming_events,
             websocket_calls,
             websocket_events,
-            responses_api_overhead_ms,
-            responses_api_inference_time_ms,
         }
     }
 }
